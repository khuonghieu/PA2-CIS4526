{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "import matplotlib\n",
    "import graphviz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#szDatasetPath = 'breast_cancer.csv'\n",
    "szDatasetPath = 'titanic_train.csv'\n",
    "\n",
    "'''\n",
    "Read the data from the csv file\n",
    "listColNames[j] stores the jth column name\n",
    "listData[i][:-1] are the features of the ith example\n",
    "listData[i][-1] is the target value of the ith example\n",
    "'''\n",
    "listColNames = [] # The list of column names\n",
    "listData = [] # The list of feature vectors of all the examples\n",
    "nRow = 0\n",
    "with open(szDatasetPath) as csvFile:\n",
    "    csvReader = csv.reader(csvFile, delimiter=',')\n",
    "    for row in csvReader:\n",
    "        if 0 == nRow:\n",
    "            listColNames = row\n",
    "        else:\n",
    "            listData.append(row)\n",
    "        nRow += 1\n",
    "\n",
    "'''\n",
    "Scan the data and store the unique values of each column.\n",
    "listColUniqueVals[j] stores a list of unique values of the jth column\n",
    "'''\n",
    "listColUniqueVals = [[] for i in range(len(listColNames))]\n",
    "for example in listData:\n",
    "    for i in range(len(example)):\n",
    "        if example[i] not in listColUniqueVals[i]:\n",
    "            listColUniqueVals[i].append(example[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First_class', 'Sex', 'Age', 'SibSp', 'ParCh', 'Embarked', 'Survived']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listColNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '1'],\n",
       " ['0', '1'],\n",
       " ['0', '1'],\n",
       " ['0', '1'],\n",
       " ['1', '0'],\n",
       " ['0', '1'],\n",
       " ['1', '0']]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listColUniqueVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate entropy of an array\n",
    "def entropy(labels):\n",
    "    prob_dict = {x:labels.count(x)/len(labels) for x in labels}\n",
    "    probs = np.array(list(prob_dict.values()))\n",
    "\n",
    "    return - probs.dot(np.log2(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the value of information gain = entropy before - entropy after\n",
    "def informationGain(parent, left, right):\n",
    "    entropyAfter = (len(left)/len(parent))*entropy(left) + (len(right)/len(parent))*entropy(right)\n",
    "    return (entropy(parent) - entropyAfter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainErrorRate(parent,left,right):\n",
    "    maxCountLeft=0\n",
    "    maxCountRight=0\n",
    "    if(left.count(1)>=left.count(0)):\n",
    "        maxCountLeft=left.count(1)\n",
    "    else:\n",
    "        maxCountLeft=left.count(0)\n",
    "    if(right.count(1)>=right.count(0)):\n",
    "        maxCountRight=right.count(1)\n",
    "    else:\n",
    "        maxCountRight=right.count(0)\n",
    "    return 1-(maxCountLeft+maxCountRight)/len(parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encoder to use when encoding features and labels\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the label array\n",
    "classCol = [row[-1] for row in listData]\n",
    "classColEncoded = le.fit_transform(classCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First_class\n",
      "Train error  0.4061624649859944  split  0.5\n",
      "\n",
      "Sex\n",
      "Train error  0.4061624649859944  split  0.5\n",
      "\n",
      "Age\n",
      "Train error  0.4061624649859944  split  0.5\n",
      "\n",
      "SibSp\n",
      "Train error  0.4061624649859944  split  0.5\n",
      "\n",
      "ParCh\n",
      "Train error  0.4061624649859944  split  0.5\n",
      "\n",
      "Embarked\n",
      "Train error  0.4061624649859944  split  0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#New list data to store encoded feature\n",
    "newListData = []\n",
    "#Iterate through all features\n",
    "for i in range(0,len(listColNames)-1):\n",
    "    #Create a feature array, then encode it for decision tree\n",
    "    featureCol = [row[i] for row in listData]\n",
    "    featureCol = le.fit_transform(featureCol)\n",
    "    newListData.append(featureCol)\n",
    "    #Print out feature values and feature names, for debug\n",
    "    #print(featureCol)\n",
    "    print(listColNames[i])\n",
    "    \n",
    "    #Variables to save best split point\n",
    "    bestSplit = 0\n",
    "    maxInfoGain = 0\n",
    "    \n",
    "    #Since the encoded features are ints like 0,1,2,3,4,5, then we separate the data by using 0.5,1.5,2.5,3.5,etc\n",
    "    for i in range(len(listColUniqueVals[i])):\n",
    "        i2= i+0.5\n",
    "        \n",
    "        #Label arrays of 2 parts of the separated data, will be used to calculate entropy\n",
    "        left = []\n",
    "        right = []\n",
    "        for x in range(len(featureCol)):\n",
    "            if(featureCol[x]<i2):\n",
    "                left.append(classColEncoded[x])\n",
    "            elif(featureCol[x]>i2):\n",
    "                right.append(classColEncoded[x])\n",
    "        \n",
    "        #Print entropy and information gain, for debug\n",
    "        #print(\"left node entropy \" + str(i2) + \": \"+str(entropy(left)))\n",
    "        #print(\"right node entropy \" + str(i2) + \": \"+str(entropy(right)))\n",
    "        #print(\"info gained \",str(i2),str(informationGain(classColEncoded.tolist(),left,right)))\n",
    "        \n",
    "        #Choose best information gain value to split\n",
    "        infoGain = informationGain(classColEncoded.tolist(),left,right)\n",
    "        if(infoGain > maxInfoGain):\n",
    "            maxInfoGain = infoGain\n",
    "            bestSplit = i2\n",
    "\n",
    "    print(\"Train error \",trainErrorRate(classColEncoded.tolist(),left,right),\" split \",bestSplit)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert and transpose new listData\n",
    "encodedData = np.array(newListData)\n",
    "encodedData=encodedData.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"250pt\" height=\"195pt\"\n",
       " viewBox=\"0.00 0.00 250.00 195.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 191)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-191 246,-191 246,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#f7d7c0\" stroke=\"#000000\" points=\"180.5,-187 61.5,-187 61.5,-104 180.5,-104 180.5,-187\"/>\n",
       "<text text-anchor=\"middle\" x=\"121\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[1] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"121\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.974</text>\n",
       "<text text-anchor=\"middle\" x=\"121\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 714</text>\n",
       "<text text-anchor=\"middle\" x=\"121\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [424, 290]</text>\n",
       "<text text-anchor=\"middle\" x=\"121\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = y[0]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#eca26c\" stroke=\"#000000\" points=\"112,-68 0,-68 0,0 112,0 112,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"56\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.732</text>\n",
       "<text text-anchor=\"middle\" x=\"56\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 453</text>\n",
       "<text text-anchor=\"middle\" x=\"56\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [360, 93]</text>\n",
       "<text text-anchor=\"middle\" x=\"56\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = y[0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M96.7964,-103.9815C91.6529,-95.1585 86.2123,-85.8258 81.0384,-76.9506\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.0344,-75.1402 75.9743,-68.2637 77.987,-78.6656 84.0344,-75.1402\"/>\n",
       "<text text-anchor=\"middle\" x=\"69.6053\" y=\"-88.7388\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#79bded\" stroke=\"#000000\" points=\"242,-68 130,-68 130,0 242,0 242,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.804</text>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 261</text>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [64, 197]</text>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = y[1]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.2036,-103.9815C150.3471,-95.1585 155.7877,-85.8258 160.9616,-76.9506\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"164.013,-78.6656 166.0257,-68.2637 157.9656,-75.1402 164.013,-78.6656\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.3947\" y=\"-88.7388\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fc8e94d4090>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisiontree = tree.DecisionTreeClassifier(max_depth=1,criterion='entropy')\n",
    "decisiontree.fit(encodedData,classColEncoded)\n",
    "dot_data = tree.export_graphviz(decisiontree, out_file=None,filled=True, class_names=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7801120448179272\n"
     ]
    }
   ],
   "source": [
    "print(decisiontree.score(encodedData,classColEncoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
